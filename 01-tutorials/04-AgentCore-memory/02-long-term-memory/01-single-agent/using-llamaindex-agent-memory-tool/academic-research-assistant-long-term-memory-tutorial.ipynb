{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex with AgentCore Memory - Academic Research Assistant (Long-term Memory)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to integrate Amazon Bedrock AgentCore Memory capabilities with LlamaIndex to create an Academic Research Assistant with **long-term memory** persistence across multiple research sessions - allowing the assistant to build cumulative knowledge over weeks and months of research work.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "![LlamaIndex AgentCore Long-Term Memory Architecture](LlamaIndex-AgentCore-LTM-Arch.png)\n",
    "\n",
    "## Tutorial Details\n",
    "\n",
    "**Tutorial Details:**\n",
    "- **Tutorial type**: Long-term Cross-Session Memory\n",
    "- **Agent usecase**: Academic Research Assistant\n",
    "- **Agentic Framework**: LlamaIndex\n",
    "- **LLM model**: Anthropic Claude 3.7 Sonnet\n",
    "- **Tutorial components**: AgentCore Long-term Memory, LlamaIndex Agent, Research Tools\n",
    "- **Example complexity**: Advanced\n",
    "\n",
    "## Business Value\n",
    "\n",
    "**Enterprise Research Intelligence**: Transform your research workflow with persistent AI memory that accumulates institutional knowledge, tracks research evolution, and maintains comprehensive academic context across projects and time periods.\n",
    "\n",
    "**Key Professional Advantages:**\n",
    "- **Research Continuity**: Seamless knowledge transfer between research phases and team members\n",
    "- **Institutional Memory**: Preserve critical research insights, methodologies, and findings permanently\n",
    "- **Cross-Project Intelligence**: Identify patterns and connections across multiple research initiatives\n",
    "- **Grant Proposal Excellence**: Leverage historical research data for compelling funding applications\n",
    "- **Academic Collaboration**: Maintain detailed context for multi-year collaborative research projects\n",
    "- **Publication Strategy**: Track research themes and citation networks for strategic publication planning\n",
    "\n",
    "## Long-Term Memory Configuration\n",
    "\n",
    "**Technical Setup**: This tutorial uses AgentCore Memory with Semantic Strategy for 12-month retention:\n",
    "- **Memory Type**: Semantic strategy with automatic insight extraction\n",
    "- **Retention**: 365-day event expiry for research continuity\n",
    "- **Cross-Session**: Same actor_id + memory_id, different session_id per research period\n",
    "- **Search Capability**: Built-in memory retrieval tool for semantic search across research history\n",
    "\n",
    "## Technical Overview\n",
    "\n",
    "**Key Long-Term Memory Components:**\n",
    "1. **Semantic Strategy Configuration**: Uses SemanticStrategy for automatic insight extraction with 365-day retention\n",
    "2. **Cross-Session Persistence**: Same actor_id + memory_id, different session_id per period enables knowledge continuity\n",
    "3. **Custom Memory Search Tool**: Wraps AgentCore's native search_long_term_memories() in LlamaIndex FunctionTool\n",
    "4. **Semantic Processing Pipeline**: 90-second wait for conversational events ‚Üí semantic memories conversion\n",
    "5. **Dynamic Session Management**: Uses memory.context.session_id for flexible session handling\n",
    "\n",
    "**You'll learn to:**\n",
    "\n",
    "- Create persistent AgentCore Memory across multiple research sessions\n",
    "- Build cumulative research knowledge over time\n",
    "- Implement semantic search across research history\n",
    "- Track research evolution and expertise development\n",
    "- Test cross-session memory persistence and retrieval\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.10+\n",
    "- AWS account with appropriate permissions\n",
    "- AWS IAM role with AgentCore Memory permissions:\n",
    "  - `bedrock-agentcore:CreateMemory`\n",
    "  - `bedrock-agentcore:CreateEvent`\n",
    "  - `bedrock-agentcore:ListEvents`\n",
    "  - `bedrock-agentcore:RetrieveMemories`\n",
    "- Access to Amazon Bedrock models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries including semantic strategy toolkit\n",
    "%pip install llama-index-memory-bedrock-agentcore llama-index-llms-bedrock-converse boto3 bedrock-agentcore-starter-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required components\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager\n",
    "from bedrock_agentcore.memory.session import MemorySessionManager\n",
    "from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies.semantic import SemanticStrategy\n",
    "from llama_index.memory.bedrock_agentcore import AgentCoreMemory, AgentCoreMemoryContext\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: AgentCore Memory Configuration\n",
    "\n",
    "Create or get the AgentCore Memory resource for long-term research knowledge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AgentCore Memory with Semantic Strategy for long-term persistence\n",
    "region = os.getenv('AWS_REGION', 'us-east-1')\n",
    "memory_manager = MemoryManager(region_name=region)\n",
    "\n",
    "try:\n",
    "    # Create memory with semantic strategy for automatic insight extraction\n",
    "    memory = memory_manager.get_or_create_memory(\n",
    "        name=f'AcademicResearchSemantic_{int(datetime.now().timestamp())}',\n",
    "        strategies=[SemanticStrategy(name=\"researchLongTermMemory\")],\n",
    "        event_expiry_days=365  # 12-month retention for research records\n",
    "    )\n",
    "    memory_id = memory.get('id')\n",
    "    print(f\"‚úÖ Created Semantic Memory: {memory_id}\")\n",
    "    print(f\"   Status: {memory.get('status')}\")\n",
    "    print(f\"   Strategies: {[s.get('name') if isinstance(s, dict) else str(s) for s in memory.get('strategies', [])]}\")\n",
    "    \n",
    "    # Wait for memory to become ACTIVE\n",
    "    if memory.get('status') != 'ACTIVE':\n",
    "        print(f\"\\n‚è≥ Waiting for memory to become ACTIVE (currently {memory.get('status')})...\")\n",
    "        import time\n",
    "        max_wait = 300  # 5 minutes max\n",
    "        waited = 0\n",
    "        while waited < max_wait:\n",
    "            time.sleep(10)\n",
    "            waited += 10\n",
    "            # Check status\n",
    "            current_memory = memory_manager.get_memory(memory_id)\n",
    "            status = current_memory.get('status')\n",
    "            print(f\"   [{waited}s] Status: {status}\")\n",
    "            if status == 'ACTIVE':\n",
    "                print(f\"‚úÖ Memory is now ACTIVE! (took {waited} seconds)\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Memory still not ACTIVE after {max_wait}s. Proceeding anyway...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating memory: {e}\")\n",
    "    memory_id = \"your-memory-id-here\"  # Replace with existing memory ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Research Tools Implementation\n",
    "\n",
    "Define specialized tools for academic research tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_paper_summary(title: str, authors: str, key_findings: str) -> str:\n",
    "    \"\"\"Save a research paper summary with title, authors, and key findings\"\"\"\n",
    "    print(f\"üìÑ Saved paper: {title} by {authors}\")\n",
    "    return f\"Successfully saved paper summary for '{title}'\"\n",
    "\n",
    "def track_research_topic(topic: str, status: str) -> str:\n",
    "    \"\"\"Track research topic progress with current status\"\"\"\n",
    "    print(f\"üî¨ Tracking research topic: {topic} (Status: {status})\")\n",
    "    return f\"Now tracking research topic: {topic} with status {status}\"\n",
    "\n",
    "def save_research_finding(finding: str, confidence: str) -> str:\n",
    "    \"\"\"Save a research finding with confidence level\"\"\"\n",
    "    print(f\"üí° Research finding saved with {confidence} confidence\")\n",
    "    return f\"Saved research finding with {confidence} confidence level\"\n",
    "\n",
    "def update_research_status(topic: str, new_status: str, notes: str) -> str:\n",
    "    \"\"\"Update research topic status with notes\"\"\"\n",
    "    print(f\"üìä Updated {topic} status to: {new_status}\")\n",
    "    return f\"Updated research status for {topic}\"\n",
    "\n",
    "def log_research_milestone(period: str, milestone: str, details: str) -> str:\n",
    "    \"\"\"Log a research milestone with period and detailed progress\"\"\"\n",
    "    print(f\"üéØ {period} milestone: {milestone}\")\n",
    "    return f\"Logged milestone for {period}: {milestone} - {details}\"\n",
    "\n",
    "def track_research_metrics(metric_type: str, value: str, source: str, period: str) -> str:\n",
    "    \"\"\"Track specific research metrics with source and timeline\"\"\"\n",
    "    print(f\"üìä {period}: {metric_type} = {value} (from {source})\")\n",
    "    return f\"Tracked {metric_type}: {value} from {source} in {period}\"\n",
    "\n",
    "def save_research_insight(insight: str, period: str, connections: str) -> str:\n",
    "    \"\"\"Save research insights with connections to previous work\"\"\"\n",
    "    print(f\"üí° {period} insight: {insight[:50]}...\")\n",
    "    return f\"Saved {period} insight with connections: {connections}\"\n",
    "\n",
    "# Create tool objects for the agent\n",
    "research_tools = [\n",
    "    FunctionTool.from_defaults(fn=save_paper_summary),\n",
    "    FunctionTool.from_defaults(fn=track_research_topic),\n",
    "    FunctionTool.from_defaults(fn=save_research_finding),\n",
    "    FunctionTool.from_defaults(fn=update_research_status),\n",
    "    FunctionTool.from_defaults(fn=log_research_milestone),\n",
    "    FunctionTool.from_defaults(fn=track_research_metrics),\n",
    "    FunctionTool.from_defaults(fn=save_research_insight)\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Research tools created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3b: Add Memory Retrieval Tool\n",
    "\n",
    "Create a tool that allows the agent to search its long-term memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_memory_retrieval_tool(memory_id: str, actor_id: str, region: str):\n",
    "    \"\"\"Create a tool for the agent to search its own long-term memory\"\"\"\n",
    "    \n",
    "    def search_long_term_memory(query: str) -> str:\n",
    "        \"\"\"Search long-term memory for relevant research information.\n",
    "        \n",
    "        Use this tool when you need to recall:\n",
    "        - Previous research papers and findings\n",
    "        - Research topics and their status\n",
    "        - Metrics and insights from past work\n",
    "        - Research milestones and progress\n",
    "        \n",
    "        Args:\n",
    "            query: Search query describing what information you need\n",
    "        \n",
    "        Returns:\n",
    "            Relevant information from long-term memory\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from bedrock_agentcore.memory.session import MemorySessionManager\n",
    "            \n",
    "            # Create session manager\n",
    "            session_manager = MemorySessionManager(\n",
    "                memory_id=memory_id,\n",
    "                region_name=region\n",
    "            )\n",
    "            \n",
    "            # Search long-term memories in the semantic strategy namespace\n",
    "            results = session_manager.search_long_term_memories(\n",
    "                query=query,\n",
    "                namespace_prefix=\"/strategies\",  # Search in semantic strategy namespace\n",
    "                top_k=5,\n",
    "                max_results=10\n",
    "            )\n",
    "            \n",
    "            if not results:\n",
    "                return \"No relevant information found in long-term memory. This might be new information or the memory extraction may still be processing.\"\n",
    "            \n",
    "            # Format results for the agent\n",
    "            output = \"üìö Retrieved from long-term memory:\\\\n\\\\n\"\n",
    "            for i, result in enumerate(results, 1):\n",
    "                # MemoryRecord object - access content attribute\n",
    "                content = getattr(result, 'content', str(result))\n",
    "                # Truncate very long content\n",
    "                if len(content) > 300:\n",
    "                    content = content[:300] + \"...\"\n",
    "                output += f\"{i}. {content}\\\\n\\\\n\"\n",
    "            \n",
    "            return output\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"‚ö†Ô∏è Error searching memory: {str(e)}. Proceeding without historical context.\"\n",
    "    \n",
    "    return FunctionTool.from_defaults(fn=search_long_term_memory)\n",
    "\n",
    "# Create the memory retrieval tool\n",
    "memory_search_tool = create_memory_retrieval_tool(memory_id, \"academic-researcher\", region)\n",
    "\n",
    "# Add memory search to the tools list\n",
    "research_tools_with_memory = research_tools + [memory_search_tool]\n",
    "\n",
    "print(f\"‚úÖ Memory retrieval tool created! Total tools: {len(research_tools_with_memory)}\")\n",
    "print(\"   Using namespace: /strategies (for semantic strategy compatibility)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3c: Verify Memory Configuration\n",
    "\n",
    "Check that semantic strategy is properly configured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check memory configuration\n",
    "memory_info = memory_manager.get_memory(memory_id)\n",
    "print(f\"Strategies: {memory_info.get('strategies')}\")\n",
    "print(f\"Status: {memory_info.get('status')}\")\n",
    "print(f\"Name: {memory_info.get('name')}\")\n",
    "\n",
    "# Show strategy details\n",
    "strategies = memory_info.get('strategies', [])\n",
    "for strategy in strategies:\n",
    "    print(f\"\\nStrategy Details:\")\n",
    "    print(f\"  Name: {strategy.get('name')}\")\n",
    "    print(f\"  Type: {strategy.get('type')}\")\n",
    "    print(f\"  Status: {strategy.get('status')}\")\n",
    "    print(f\"  ID: {strategy.get('strategyId')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Multi-Session Agent Implementation\n",
    "\n",
    "Create helper function to simulate different research sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for LONG-TERM memory (cross-session)\n",
    "MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "RESEARCHER_ID = \"academic-researcher\"  # Same researcher across all sessions\n",
    "\n",
    "def create_research_session(session_name: str):\n",
    "    \"\"\"Create a new research session with long-term memory persistence\"\"\"\n",
    "    context = AgentCoreMemoryContext(\n",
    "        actor_id=RESEARCHER_ID,         # Same researcher\n",
    "        memory_id=memory_id,         # Same memory store (enables long-term memory)\n",
    "        session_id=f\"research-{session_name}\", # Different session per period\n",
    "        namespace=\"/academic-research\"\n",
    "    )\n",
    "    \n",
    "    memory = AgentCoreMemory(context=context)\n",
    "    llm = BedrockConverse(model=MODEL_ID)\n",
    "    agent = FunctionAgent(\n",
    "        tools=research_tools_with_memory,  # Use tools with memory search capability\n",
    "        llm=llm, \n",
    "        verbose=True,  # Enable verbose to see when memory is searched\n",
    "        system_prompt=\"\"\"You are a senior research assistant with access to long-term memory.\n",
    "        \n",
    "CRITICAL: When asked about previous research, papers, findings, or historical information, \n",
    "you MUST use the search_long_term_memory tool FIRST before responding.\n",
    "\n",
    "For example:\n",
    "- \"What research am I working on?\" ‚Üí Use search_long_term_memory(\"research topics\")\n",
    "- \"What papers have I reviewed?\" ‚Üí Use search_long_term_memory(\"papers authors\")\n",
    "- \"What findings do I have?\" ‚Üí Use search_long_term_memory(\"research findings\")\n",
    "\n",
    "Always provide conclusive, complete responses without asking follow-up questions.\\n\n",
    "Execute all requested actions immediately and completely. Provide detailed, professional responses.\"\"\"\n",
    "    )\n",
    "    \n",
    "    return agent, memory\n",
    "\n",
    "print(\"‚úÖ Multi-session Academic Research Assistant setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Week 1 Research Session - Foundation Building\n",
    "\n",
    "Start the first research session and establish foundational knowledge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WEEK 1 RESEARCH SESSION ===\n",
    "print(\"üóìÔ∏è === WEEK 1: FOUNDATION RESEARCH ===\")\n",
    "\n",
    "agent_week1, memory_week1 = create_research_session(\"week1\")\n",
    "\n",
    "# Establish research foundation\n",
    "response = await agent_week1.run(\n",
    "    \"I'm Dr. Sarah Smith from MIT starting comprehensive research on 'Machine Learning in Healthcare Applications'. \"\n",
    "    \"Track this with status 'Literature Review'. My goal is to publish a systematic review by year-end.\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "\n",
    "print(\"üéØ Week 1 Foundation:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add foundational papers with detailed metrics\n",
    "response = await agent_week1.run(\n",
    "    \"Save paper: 'Deep Learning for Medical Image Analysis' by Zhang et al (2023). \"\n",
    "    \"Key findings: CNNs achieve 95.2% accuracy in chest X-ray diagnosis, 12% improvement over radiologists, \"\n",
    "    \"trained on 100,000 images, 0.03 false positive rate.\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "print(\"üìÑ Week 1 Paper 1:\", response)\n",
    "\n",
    "response = await agent_week1.run(\n",
    "    \"Save paper: 'Transformers in Medical NLP' by Johnson et al (2023). \"\n",
    "    \"Key findings: BERT achieves 89.1% F1-score in clinical note classification, \"\n",
    "    \"struggles with rare diseases (<70% accuracy), excels at symptom extraction (94% precision).\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "print(\"üìÑ Week 1 Paper 2:\", response)\n",
    "# Explicitly track the accuracy metrics\n",
    "await agent_week1.run(\n",
    "    \"Track research metrics: metric_type 'CNN Accuracy', value '95.2%', source 'Zhang et al 2023', period 'Week 1'.\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "await agent_week1.run(\n",
    "    \"Track research metrics: metric_type 'Radiologist Improvement', value '12%', source 'Zhang et al 2023', period 'Week 1'.\",\n",
    "    memory=memory_week1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow time for semantic memory processing\n",
    "import asyncio\n",
    "print(\"\\n‚è≥ Waiting for semantic memory extraction and indexing...\")\n",
    "print(\"   (AgentCore processes conversational events in the background)\")\n",
    "await asyncio.sleep(90)  # Increased wait time for memory extraction\n",
    "print(\"‚úÖ Memory processing complete - memories should now be searchable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Week 2 Research Session - Cross-Session Memory Test\n",
    "\n",
    "Test long-term memory retrieval and add new research:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WEEK 2 RESEARCH SESSION ===\n",
    "print(\"\\nüóìÔ∏è === WEEK 2: EXPANSION (NEW SESSION) ===\")\n",
    "\n",
    "agent_week2, memory_week2 = create_research_session(\"week2\")\n",
    "\n",
    "# Test cross-session memory recall\n",
    "response = await agent_week2.run(\n",
    "    \"What research am I working on? What specific accuracy metrics have I found so far? Who are the key authors?\",\n",
    "    memory=memory_week2\n",
    ")\n",
    "\n",
    "print(\"üß† Week 2 Memory Test:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: ML in Healthcare, Zhang 95.2%, Johnson 89.1% F1-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new research building on previous knowledge\n",
    "response = await agent_week2.run(\n",
    "    \"Save paper: 'Federated Learning in Healthcare' by Brown et al (2023). \"\n",
    "    \"Key findings: Privacy-preserving ML enables multi-hospital collaboration, 87.3% accuracy across 15 hospitals, \"\n",
    "    \"23% improvement in rare disease detection when hospitals collaborate.\",\n",
    "    memory=memory_week2\n",
    ")\n",
    "print(\"üìÑ Week 2 New Paper:\", response)\n",
    "\n",
    "# Test comparative analysis across sessions\n",
    "response = await agent_week2.run(\n",
    "    \"Compare the accuracy results: Zhang's CNNs vs Johnson's BERT vs Brown's federated learning. \"\n",
    "    \"Which performs best and in what contexts?\",\n",
    "    memory=memory_week2\n",
    ")\n",
    "print(\"üìä Week 2 Comparative Analysis:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Zhang 95.2% (imaging), Johnson 89.1% (NLP), Brown 87.3% (federated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Week 3 Research Session - Analysis Phase\n",
    "\n",
    "Progress research and test detailed cross-session recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WEEK 3 RESEARCH SESSION ===\n",
    "print(\"\\nüóìÔ∏è === WEEK 3: ANALYSIS PHASE ===\")\n",
    "\n",
    "agent_week3, memory_week3 = create_research_session(\"week3\")\n",
    "\n",
    "# Update research status\n",
    "response = await agent_week3.run(\n",
    "    \"Update my 'Machine Learning in Healthcare Applications' research status to 'Analysis Phase' \"\n",
    "    \"with notes: 'Reviewed 3 key papers, identified performance patterns: imaging>NLP>federated learning'.\",\n",
    "    memory=memory_week3\n",
    ")\n",
    "print(\"üìä Week 3 Status Update:\", response)\n",
    "\n",
    "# Test detailed cross-session recall\n",
    "response = await agent_week3.run(\n",
    "    \"What evidence do I have for the claim that imaging tasks show highest ML performance in healthcare? \"\n",
    "    \"Include specific numbers and authors.\",\n",
    "    memory=memory_week3\n",
    ")\n",
    "print(\"üîç Week 3 Evidence Query:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Zhang et al CNNs 95.2% vs Johnson BERT 89.1% vs Brown federated 87.3%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Month 1 Research Session - Synthesis Phase\n",
    "\n",
    "Test comprehensive knowledge synthesis and research consolidation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MONTH 1 RESEARCH SESSION ===\n",
    "print(\"\\nüóìÔ∏è === MONTH 1: SYNTHESIS PHASE ===\")\n",
    "\n",
    "agent_month1, memory_month1 = create_research_session(\"month1\")\n",
    "\n",
    "# Update research status to synthesis phase\n",
    "response = await agent_month1.run(\n",
    "    \"Update my 'Machine Learning in Healthcare Applications' research status to 'Synthesis Phase' \"\n",
    "    \"with notes: 'Completed 3-week literature review, ready to synthesize findings into coherent framework'.\",\n",
    "    memory=memory_month1\n",
    ")\n",
    "print(\"üìä Month 1 Status Update:\", response)\n",
    "\n",
    "# Test comprehensive synthesis across all weeks\n",
    "response = await agent_month1.run(\n",
    "    \"Based on all my research so far, what is the overall performance ranking of ML approaches in healthcare? \"\n",
    "    \"Include all specific metrics and create a comprehensive comparison.\",\n",
    "    memory=memory_month1\n",
    ")\n",
    "print(\"üîç Month 1 Comprehensive Synthesis:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Ranking with Zhang 95.2% > Johnson 89.1% > Brown 87.3%, domain analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Month 2 Research Session - Writing Phase\n",
    "\n",
    "Test comprehensive recall and semantic search capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MONTH 2 RESEARCH SESSION ===\n",
    "print(\"\\nüóìÔ∏è === MONTH 2: WRITING PHASE ===\")\n",
    "\n",
    "agent_month2, memory_month2 = create_research_session(\"month2\")\n",
    "\n",
    "# Test comprehensive recall for writing\n",
    "response = await agent_month2.run(\n",
    "    \"I'm writing my systematic review paper. What are ALL the papers I've reviewed with their exact accuracy metrics? \"\n",
    "    \"I need this for my results table.\",\n",
    "    memory=memory_month2\n",
    ")\n",
    "print(\"üìù Month 2 Comprehensive Recall:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Zhang 95.2%, Johnson 89.1%, Brown 87.3% with full details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test semantic search across research history\n",
    "response = await agent_month2.run(\n",
    "    \"What do I know about rare disease detection in my research? Which papers and what specific results?\",\n",
    "    memory=memory_month2\n",
    ")\n",
    "print(\"üîç Month 2 Semantic Search:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Johnson <70% for rare diseases, Brown 23% improvement with collaboration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Month 3 Research Session - Grant Proposal Scenario\n",
    "\n",
    "Test practical application of accumulated knowledge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MONTH 3 RESEARCH SESSION ===\n",
    "print(\"\\nüóìÔ∏è === MONTH 3: GRANT PROPOSAL ===\")\n",
    "\n",
    "agent_month3, memory_month3 = create_research_session(\"month3\")\n",
    "\n",
    "# Grant proposal evidence gathering\n",
    "response = await agent_month3.run(\n",
    "    \"I'm writing an NIH grant proposal for $2M funding. What evidence can I cite about ML effectiveness in healthcare? \"\n",
    "    \"I need specific numbers, authors, years, and sample sizes.\",\n",
    "    memory=memory_month3\n",
    ")\n",
    "print(\"üí∞ Month 3 Grant Evidence:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Comprehensive citation with Zhang 95.2% (100K images), Johnson 89.1%, Brown 87.3% (15 hospitals)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test research evolution tracking with detailed milestones\n",
    "response = await agent_month3.run(\n",
    "    \"Provide a detailed timeline of my research evolution from Week 1 to now. What specific milestones, \"\n",
    "    \"metrics, and insights did I achieve each period? How did my research questions evolve?\",\n",
    "    memory=memory_month3\n",
    ")\n",
    "print(\"üìà Month 3 Research Evolution:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Week-by-week progression with specific milestones, metrics (95.2%, 89.1%, 87.3%), and insights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Final Portfolio Assessment\n",
    "\n",
    "Comprehensive test of long-term memory capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comprehensive portfolio query\n",
    "response = await agent_month3.run(\n",
    "    \"Provide my complete research portfolio: all topics I'm working on, all papers with metrics, \"\n",
    "    \"all findings, current status of each project, and how they interconnect.\",\n",
    "    memory=memory_month3\n",
    ")\n",
    "print(\"üìã Complete Research Portfolio:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Full research history with all metrics, connections between ML healthcare topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Automated Test Validation\n",
    "Run these cells to validate that memory integration is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define validation functions inline\n",
    "class TestValidator:\n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "    \n",
    "    def validate_memory_recall(self, response):\n",
    "        \"\"\"Check if agent can recall information from earlier in the session\"\"\"\n",
    "        # Check for substantive response (not just \"I don't know\")\n",
    "        has_content = len(response) > 50\n",
    "        # Check for memory indicators\n",
    "        has_memory_indicators = any(word in response.lower() for word in \n",
    "            ['earlier', 'mentioned', 'discussed', 'previously', 'you', 'we', 'our'])\n",
    "        return \"‚úÖ PASS\" if (has_content and has_memory_indicators) else \"‚ùå FAIL\"\n",
    "    \n",
    "    def validate_session_memory(self, response):\n",
    "        \"\"\"Check if agent maintains context within session\"\"\"\n",
    "        has_memory_content = len(response) > 100 and any(word in response.lower() for word in \n",
    "            ['previous', 'earlier', 'mentioned', 'discussed', 'before', 'already'])\n",
    "        return \"‚úÖ PASS\" if has_memory_content else \"‚ùå FAIL\"\n",
    "    \n",
    "    def validate_cross_reference(self, response):\n",
    "        \"\"\"Check if agent can connect current query to previous context\"\"\"\n",
    "        # Look for connecting language\n",
    "        connecting_words = ['relate', 'connection', 'previous', 'earlier', 'discussed', \n",
    "                           'mentioned', 'context', 'based on', 'as we', 'as i']\n",
    "        has_connection = any(word in response.lower() for word in connecting_words)\n",
    "        has_substance = len(response) > 80\n",
    "        return \"‚úÖ PASS\" if (has_connection and has_substance) else \"‚ùå FAIL\"\n",
    "    \n",
    "    def run_validation_summary(self, test_results):\n",
    "        print(\"üß™ COMPREHENSIVE TEST VALIDATION SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        total_tests = len(test_results)\n",
    "        passed_tests = sum(1 for result in test_results.values() if \"PASS\" in result)\n",
    "        pass_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0\n",
    "        \n",
    "        for test_name, result in test_results.items():\n",
    "            print(f\"{test_name}: {result}\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üìä Overall Pass Rate: {passed_tests}/{total_tests} ({pass_rate:.1f}%)\")\n",
    "        \n",
    "        if pass_rate >= 80:\n",
    "            print(\"‚úÖ EXCELLENT: Memory integration working correctly!\")\n",
    "        elif pass_rate >= 60:\n",
    "            print(\"‚ö†Ô∏è  GOOD: Most memory features working, some issues to investigate\")\n",
    "        else:\n",
    "            print(\"‚ùå NEEDS ATTENTION: Memory integration has significant issues\")\n",
    "        \n",
    "        return pass_rate\n",
    "\n",
    "validator = TestValidator()\n",
    "print(\"‚úÖ Validation functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all validation tests\n",
    "test_results = {}\n",
    "\n",
    "# Test 1: Memory recall - can the agent recall what was discussed?\n",
    "response1 = await agent_month3.run(\"What have we discussed so far in this session?\", memory=memory_month3)\n",
    "test_results['Memory Recall'] = validator.validate_memory_recall(str(response1))\n",
    "print(f\"Response 1 length: {len(str(response1))} chars\")\n",
    "\n",
    "# Test 2: Session memory - does the agent maintain context?\n",
    "response2 = await agent_month3.run(\"What did we talk about earlier?\", memory=memory_month3)\n",
    "test_results['Session Memory'] = validator.validate_session_memory(str(response2))\n",
    "print(f\"Response 2 length: {len(str(response2))} chars\")\n",
    "\n",
    "# Test 3: Cross-reference capability - can it connect to previous context?\n",
    "response3 = await agent_month3.run(\"How does this relate to what we discussed before?\", memory=memory_month3)\n",
    "test_results['Cross Reference'] = validator.validate_cross_reference(str(response3))\n",
    "print(f\"Response 3 length: {len(str(response3))} chars\")\n",
    "\n",
    "# Display results\n",
    "validator.run_validation_summary(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've demonstrated:\n",
    "\n",
    "‚úÖ **Long-term Memory Integration**: Using AgentCore Memory with LlamaIndex for cross-session persistence\n",
    "\n",
    "‚úÖ **Cumulative Knowledge Building**: Research knowledge accumulates over weeks and months\n",
    "\n",
    "‚úÖ **Semantic Retrieval**: Assistant can find related information based on concepts across sessions\n",
    "\n",
    "‚úÖ **Research Evolution Tracking**: Natural progression from literature review to analysis to writing\n",
    "\n",
    "‚úÖ **Cross-Session Synthesis**: Connecting findings and insights across multiple research sessions\n",
    "\n",
    "‚úÖ **Practical Applications**: Grant proposal support and comprehensive portfolio management\n",
    "\n",
    "The Academic Research Assistant showcases how long-term memory transforms the assistant into a persistent research companion that grows smarter over time, maintaining complete research history and enabling sophisticated knowledge retrieval across extended research projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Let's delete the memory to clean up the resources used in this notebook:\n",
    "\n",
    "**Note**: Only run this if you want to permanently delete the memory. The memory_id variable should contain the ID from the memory created earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up AgentCore Memory resource\n",
    "try:\n",
    "    from bedrock_agentcore.memory import MemoryClient\n",
    "    \n",
    "    client = MemoryClient(region_name=region)\n",
    "    client.delete_memory(memory_id)\n",
    "    print(f\"‚úÖ Successfully deleted memory: {memory_id}\")\n",
    "    \n",
    "except NameError as e:\n",
    "    print(f\"‚ö†Ô∏è  Variable not defined: {e}\")\n",
    "    print(\"Run the notebook from the beginning or set variables manually:\")\n",
    "    print(\"# memory_id = 'your-memory-id-here'\")\n",
    "    print(\"# region = 'us-east-1'\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error deleting memory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
