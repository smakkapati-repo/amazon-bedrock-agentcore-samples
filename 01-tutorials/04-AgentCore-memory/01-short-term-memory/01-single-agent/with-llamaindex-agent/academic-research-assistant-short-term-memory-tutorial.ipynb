{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex with AgentCore Memory - Academic Research Assistant (Short-term Memory)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to integrate Amazon Bedrock AgentCore Memory capabilities with LlamaIndex to create an Academic Research Assistant. We'll focus on **short-term memory** persistence within a single research session - allowing the assistant to remember papers, findings, and research context throughout a conversation.\n",
    "\n",
    "## Tutorial Details\n",
    "\n",
    "| Information         | Details                                                                          |\n",
    "|:--------------------|:---------------------------------------------------------------------------------|\n",
    "| Tutorial type       | Short-term Conversational Memory                                                |\n",
    "| Agent usecase       | Academic Research Assistant                                                      |\n",
    "| Agentic Framework   | LlamaIndex                                                                       |\n",
    "| LLM model           | Anthropic Claude 3.7 Sonnet                                                  |\n",
    "| Tutorial components | AgentCore Short-term Memory, LlamaIndex Agent, Research Tools                   |\n",
    "| Example complexity  | Beginner                                                                         |\n",
    "\n",
    "You'll learn to:\n",
    "- Create AgentCore Memory for research data persistence\n",
    "- Use LlamaIndex native memory integration\n",
    "- Build research-specific tools for paper analysis\n",
    "- Maintain research context within a single session\n",
    "- Test memory boundaries and session isolation\n",
    "\n",
    "## Scenario Context\n",
    "\n",
    "In this example, we'll create an \"Academic Research Assistant\" that helps researchers track papers, findings, and research topics within a single research session. The assistant uses AgentCore Memory to maintain context about papers reviewed, key findings discovered, and research progress throughout the conversation.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "![LlamaIndex AgentCore Short-Term Memory Architecture](LlamaIndex-AgentCore-STM-Arch.png)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.10+\n",
    "- AWS account with appropriate permissions\n",
    "- AWS IAM role with AgentCore Memory permissions:\n",
    "  - `bedrock-agentcore:CreateMemory`\n",
    "  - `bedrock-agentcore:CreateEvent`\n",
    "  - `bedrock-agentcore:ListEvents`\n",
    "  - `bedrock-agentcore:RetrieveMemories`\n",
    "- Access to Amazon Bedrock models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "%pip install llama-index-memory-bedrock-agentcore llama-index-llms-bedrock-converse boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required components\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from llama_index.memory.bedrock_agentcore import AgentCoreMemory, AgentCoreMemoryContext\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: AgentCore Memory Configuration\n",
    "\n",
    "Create or get the AgentCore Memory resource for our research assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AgentCore Memory resource\n",
    "region = os.getenv('AWS_REGION', 'us-east-1')\n",
    "client = MemoryClient(region_name=region)\n",
    "\n",
    "try:\n",
    "    response = client.create_memory_and_wait(\n",
    "        name=f'AcademicResearchShortTerm_{int(datetime.now().timestamp())}',\n",
    "        description='Academic research assistant short-term memory for single session context',\n",
    "        strategies=[],\n",
    "        event_expiry_days=7,\n",
    "        max_wait=300,\n",
    "        poll_interval=10\n",
    "    )\n",
    "    memory_id = response['id']\n",
    "    print(f\"‚úÖ Created AgentCore Memory: {memory_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating memory: {e}\")\n",
    "    memory_id = \"your-memory-id-here\"  # Replace with existing memory ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Research Tools Implementation\n",
    "\n",
    "Define specialized tools for academic research tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_paper_summary(title: str, authors: str, key_findings: str) -> str:\n",
    "    \"\"\"Save a research paper summary with title, authors, and key findings\"\"\"\n",
    "    print(f\"üìÑ Saved paper: {title} by {authors}\")\n",
    "    return f\"Successfully saved paper summary for '{title}'\"\n",
    "\n",
    "def track_research_topic(topic: str, status: str) -> str:\n",
    "    \"\"\"Track research topic progress with current status\"\"\"\n",
    "    print(f\"üî¨ Tracking research topic: {topic} (Status: {status})\")\n",
    "    return f\"Now tracking research topic: {topic} with status {status}\"\n",
    "\n",
    "def save_research_finding(finding: str, confidence: str) -> str:\n",
    "    \"\"\"Save a research finding with confidence level\"\"\"\n",
    "    print(f\"üí° Research finding saved with {confidence} confidence\")\n",
    "    return f\"Saved research finding with {confidence} confidence level\"\n",
    "\n",
    "# Create tool objects for the agent\n",
    "research_tools = [\n",
    "    FunctionTool.from_defaults(fn=save_paper_summary),\n",
    "    FunctionTool.from_defaults(fn=track_research_topic),\n",
    "    FunctionTool.from_defaults(fn=save_research_finding)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: LlamaIndex Agent Implementation\n",
    "\n",
    "Create the research assistant agent with short-term memory context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for SHORT-TERM memory (single session)\n",
    "MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "\n",
    "# Create memory context for single session\n",
    "context = AgentCoreMemoryContext(\n",
    "    actor_id=\"academic-researcher\",\n",
    "    memory_id=memory_id,\n",
    "    session_id=\"research-session-today\",  # Same session throughout\n",
    "    namespace=\"/academic-research\"\n",
    ")\n",
    "\n",
    "# Initialize AgentCore Memory and LLM\n",
    "agentcore_memory = AgentCoreMemory(context=context)\n",
    "llm = BedrockConverse(model=MODEL_ID)\n",
    "\n",
    "# Create the research assistant agent\n",
    "research_agent = FunctionAgent(\n",
    "    tools=research_tools,\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Academic Research Assistant with short-term memory is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Testing Short-Term Memory Capabilities\n",
    "\n",
    "Let's test our research assistant's short-term memory through a comprehensive research session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Session Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize research session with detailed context\n",
    "response = await research_agent.run(\n",
    "    \"I'm Dr. Sarah Smith from MIT's Computer Science Department, starting research on 'Machine Learning in Healthcare Applications'. \"\n",
    "    \"Track this topic with status 'Literature Review'.\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"üéØ Session Initialization:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Adding Research Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add first paper with detailed metrics\n",
    "response = await research_agent.run(\n",
    "    \"Save paper: 'Deep Learning for Medical Image Analysis' by Zhang et al. \"\n",
    "    \"Key findings: CNNs achieve 95.2% accuracy in chest X-ray diagnosis, 12% improvement over radiologists, \"\n",
    "    \"trained on 100,000 images with 0.03 false positive rate.\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"üìÑ Paper 1 Added:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add second paper with contrasting findings\n",
    "response = await research_agent.run(\n",
    "    \"Save paper: 'Transformers in Medical NLP' by Johnson et al. \"\n",
    "    \"Key findings: BERT models achieve 89.1% F1-score in clinical note classification, \"\n",
    "    \"struggle with rare diseases (<70% accuracy), excel at symptom extraction (94% precision).\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"üìÑ Paper 2 Added:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Identity and Context Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test identity and research context recall\n",
    "response = await research_agent.run(\n",
    "    \"What's my name, institution, and current research focus?\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"üß† Identity Recall Test:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Dr. Sarah Smith, MIT, Machine Learning in Healthcare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Detailed Metrics Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test specific metric recall\n",
    "response = await research_agent.run(\n",
    "    \"What were the exact accuracy percentages mentioned in the papers I reviewed? \"\n",
    "    \"Which authors wrote about CNNs vs Transformers?\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"üìä Detailed Metrics Recall:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Zhang et al - CNNs 95.2%, Johnson et al - BERT 89.1%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 5: Contextual Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test contextual understanding and reasoning\n",
    "response = await research_agent.run(\n",
    "    \"Based on the papers I've reviewed, which approach would be better for analyzing \"\n",
    "    \"chest X-rays vs clinical notes? Explain your reasoning.\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"ü§î Contextual Reasoning Test:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: CNNs for X-rays (Zhang paper), Transformers for clinical notes (Johnson paper)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 6: Research Finding Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add synthesized research finding\n",
    "response = await research_agent.run(\n",
    "    \"Based on Zhang's CNN results (95.2% accuracy) and Johnson's Transformer results (89.1% F1-score), \"\n",
    "    \"I conclude that deep learning models consistently achieve >85% accuracy in healthcare tasks. \"\n",
    "    \"This finding has high confidence. Save it.\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"üî¨ Research Finding Synthesis:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 7: Cross-Reference Capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cross-referencing between findings and papers\n",
    "response = await research_agent.run(\n",
    "    \"How does my research finding about >85% accuracy relate to the specific results \"\n",
    "    \"from Zhang and Johnson? What evidence supports this conclusion?\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"üîó Cross-Reference Test:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Reference to Zhang 95.2% and Johnson 89.1% as supporting evidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 8: Practical Application Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test practical application of accumulated knowledge\n",
    "response = await research_agent.run(\n",
    "    \"I'm writing a grant proposal for healthcare AI research. What evidence can I cite \"\n",
    "    \"about deep learning effectiveness? Include specific numbers and authors.\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"üìù Grant Proposal Support:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Comprehensive summary with Zhang 95.2%, Johnson 89.1%, synthesis finding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Testing Session Boundaries\n",
    "\n",
    "Let's test the boundaries of short-term memory by creating a different session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a different session context\n",
    "new_session_context = AgentCoreMemoryContext(\n",
    "    actor_id=\"academic-researcher\",\n",
    "    memory_id=memory_id,\n",
    "    session_id=\"different-research-session\",  # Different session ID\n",
    "    namespace=\"/academic-research\"\n",
    ")\n",
    "\n",
    "new_session_memory = AgentCoreMemory(context=new_session_context)\n",
    "\n",
    "# Test memory isolation\n",
    "response = await research_agent.run(\n",
    "    \"What research have I been working on? What specific accuracy numbers did I find?\",\n",
    "    memory=new_session_memory\n",
    ")\n",
    "\n",
    "print(\"üöß Session Boundary Test (Different Session):\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Limited or no recall from previous session (short-term memory boundary)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return to original session to verify persistence\n",
    "response = await research_agent.run(\n",
    "    \"Now back in my original session - what were the accuracy numbers from Zhang and Johnson again?\",\n",
    "    memory=agentcore_memory  # Original session memory\n",
    ")\n",
    "\n",
    "print(\"üîÑ Original Session Return:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ Expected: Full recall of Zhang 95.2%, Johnson 89.1%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Automated Test Validation\n",
    "Run these cells to validate that memory integration is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define validation functions inline\n",
    "class TestValidator:\n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "    \n",
    "    def validate_memory_recall(self, response):\n",
    "        \"\"\"Check if agent can recall information from earlier in the session\"\"\"\n",
    "        # Check for substantive response (not just \"I don't know\")\n",
    "        has_content = len(response) > 50\n",
    "        # Check for memory indicators\n",
    "        has_memory_indicators = any(word in response.lower() for word in \n",
    "            ['earlier', 'mentioned', 'discussed', 'previously', 'you', 'we', 'our'])\n",
    "        return \"‚úÖ PASS\" if (has_content and has_memory_indicators) else \"‚ùå FAIL\"\n",
    "    \n",
    "    def validate_session_memory(self, response):\n",
    "        \"\"\"Check if agent maintains context within session\"\"\"\n",
    "        has_memory_content = len(response) > 100 and any(word in response.lower() for word in \n",
    "            ['previous', 'earlier', 'mentioned', 'discussed', 'before', 'already'])\n",
    "        return \"‚úÖ PASS\" if has_memory_content else \"‚ùå FAIL\"\n",
    "    \n",
    "    def validate_cross_reference(self, response):\n",
    "        \"\"\"Check if agent can connect current query to previous context\"\"\"\n",
    "        # Look for connecting language\n",
    "        connecting_words = ['relate', 'connection', 'previous', 'earlier', 'discussed', \n",
    "                           'mentioned', 'context', 'based on', 'as we', 'as i']\n",
    "        has_connection = any(word in response.lower() for word in connecting_words)\n",
    "        has_substance = len(response) > 80\n",
    "        return \"‚úÖ PASS\" if (has_connection and has_substance) else \"‚ùå FAIL\"\n",
    "    \n",
    "    def run_validation_summary(self, test_results):\n",
    "        print(\"üß™ COMPREHENSIVE TEST VALIDATION SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        total_tests = len(test_results)\n",
    "        passed_tests = sum(1 for result in test_results.values() if \"PASS\" in result)\n",
    "        pass_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0\n",
    "        \n",
    "        for test_name, result in test_results.items():\n",
    "            print(f\"{test_name}: {result}\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üìä Overall Pass Rate: {passed_tests}/{total_tests} ({pass_rate:.1f}%)\")\n",
    "        \n",
    "        if pass_rate >= 80:\n",
    "            print(\"‚úÖ EXCELLENT: Memory integration working correctly!\")\n",
    "        elif pass_rate >= 60:\n",
    "            print(\"‚ö†Ô∏è  GOOD: Most memory features working, some issues to investigate\")\n",
    "        else:\n",
    "            print(\"‚ùå NEEDS ATTENTION: Memory integration has significant issues\")\n",
    "        \n",
    "        return pass_rate\n",
    "\n",
    "validator = TestValidator()\n",
    "print(\"‚úÖ Validation functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all validation tests\n",
    "test_results = {}\n",
    "\n",
    "# Test 1: Memory recall - can the agent recall what was discussed?\n",
    "response1 = await research_agent.run(\"What have we discussed so far in this session?\", memory=agentcore_memory)\n",
    "test_results['Memory Recall'] = validator.validate_memory_recall(str(response1))\n",
    "print(f\"Response 1 length: {len(str(response1))} chars\")\n",
    "\n",
    "# Test 2: Session memory - does the agent maintain context?\n",
    "response2 = await research_agent.run(\"What did we talk about earlier?\", memory=agentcore_memory)\n",
    "test_results['Session Memory'] = validator.validate_session_memory(str(response2))\n",
    "print(f\"Response 2 length: {len(str(response2))} chars\")\n",
    "\n",
    "# Test 3: Cross-reference capability - can it connect to previous context?\n",
    "response3 = await research_agent.run(\"How does this relate to what we discussed before?\", memory=agentcore_memory)\n",
    "test_results['Cross Reference'] = validator.validate_cross_reference(str(response3))\n",
    "print(f\"Response 3 length: {len(str(response3))} chars\")\n",
    "\n",
    "# Display results\n",
    "validator.run_validation_summary(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've demonstrated:\n",
    "\n",
    "‚úÖ **Short-term Memory Integration**: Using AgentCore Memory with LlamaIndex for session-scoped persistence\n",
    "\n",
    "‚úÖ **Research-Specific Tools**: Paper summaries, topic tracking, and findings storage\n",
    "\n",
    "‚úÖ **Contextual Conversations**: Assistant remembers detailed information within the session\n",
    "\n",
    "‚úÖ **Cross-Reference Capability**: Connecting findings across multiple papers and interactions\n",
    "\n",
    "‚úÖ **Session Boundaries**: Memory isolation between different conversation sessions\n",
    "\n",
    "‚úÖ **Practical Applications**: Grant proposal support and research synthesis\n",
    "\n",
    "The Academic Research Assistant showcases how short-term memory enables natural, contextual conversations within a single research session while maintaining clear boundaries between different conversation threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Let's delete the memory to clean up the resources used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up AgentCore Memory resource\n",
    "try:\n",
    "    client.delete_memory(memory_id)\n",
    "    print(f\"‚úÖ Successfully deleted memory: {memory_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error deleting memory: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
